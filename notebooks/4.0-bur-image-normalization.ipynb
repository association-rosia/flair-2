{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåÅ Image normalization statistiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import torch\n",
    "import json\n",
    "import torchvision.transforms as T\n",
    "\n",
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ©Ô∏è Mean & Std for Aerial images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tif(path_file):\n",
    "    with rasterio.open(path_file) as f:\n",
    "        image = f.read()\n",
    "        image = torch.from_numpy(image)\n",
    "        image = image.type(torch.uint8)  # from 0 to 255\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(template_path_image, filename, num_channels, open_file, max_channels):\n",
    "    # Initialize variables to store accumulated pixel values\n",
    "    channel_sum = torch.zeros(num_channels)\n",
    "    channel_squared_diff_sum = torch.zeros(num_channels)\n",
    "    total_pixels = 0\n",
    "\n",
    "    # Iterate over the image paths\n",
    "    list_path_image = glob(template_path_image, recursive=True)\n",
    "    for path_image in tqdm(list_path_image, desc='Compute sum by channel'):\n",
    "        # Open the image\n",
    "        image = open_file(path_image)\n",
    "        image = image / max_channels\n",
    "            \n",
    "        # Reshape the image to a 2D array of pixels (height * width, channels)\n",
    "        pixels = image.view(-1, num_channels)\n",
    "        \n",
    "        # Accumulate channel sums\n",
    "        channel_sum += pixels.sum(dim=0)\n",
    "        \n",
    "        # Update the total number of pixels\n",
    "        total_pixels += pixels.shape[0]\n",
    "\n",
    "    # Compute mean values for each channel\n",
    "    channel_mean = channel_sum / total_pixels\n",
    "\n",
    "    for path_image in tqdm(list_path_image, desc='Compute squared diff sum by channel'):\n",
    "        # Open the image\n",
    "        image = read_tif(path_image)\n",
    "        image = image / max_channels\n",
    "            \n",
    "        # Reshape the image to a 2D array of pixels (height * width, channels)\n",
    "        pixels = image.view(-1, num_channels)\n",
    "        \n",
    "        # Accumulate squared differences from the mean\n",
    "        diff = pixels - channel_mean\n",
    "        channel_squared_diff_sum += (diff * diff).sum(dim=0)\n",
    "\n",
    "    # Compute standard deviation values for each channel\n",
    "    channel_std = torch.sqrt(channel_squared_diff_sum / total_pixels)\n",
    "\n",
    "    dataset_dict = {\n",
    "        'mean': channel_mean.tolist(),\n",
    "        'std': channel_std.tolist()\n",
    "    }\n",
    "\n",
    "    with open(filename, 'w', encoding='UTF8') as f:\n",
    "        json.dump(dataset_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c1400302df4694a923bc7fbf56c5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute sum by channel:   0%|          | 0/61712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b6eff5c5454ef7bf10fd0dde9e7c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute squared diff sum by channel:   0%|          | 0/61712 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "template_path_image = os.path.join(os.pardir, 'data', 'raw', 'train', 'aerial', '**', '*.tif')\n",
    "filename = os.path.join(os.pardir, 'data', 'raw', 'aerial_pixels_metadata.json', )\n",
    "compute_stats(template_path_image, filename, 5, read_tif, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(template_path_image, filename, num_channels, open_file, max_channels):\n",
    "    # Initialize variables to store accumulated pixel values\n",
    "    channel_sum = torch.zeros(num_channels)\n",
    "    channel_squared_diff_sum = torch.zeros(num_channels)\n",
    "    total_pixels = 0\n",
    "\n",
    "    # Iterate over the image paths\n",
    "    list_path_image = glob(template_path_image, recursive=True)\n",
    "    for path_image in tqdm(list_path_image, desc='Compute sum by channel'):\n",
    "        # Open the image\n",
    "        image = open_file(path_image)\n",
    "        image = image / max_channels\n",
    "            \n",
    "        # Reshape the image to a 2D array of pixels (height * width, channels)\n",
    "        pixels = image.view(-1, num_channels)\n",
    "        \n",
    "        # Accumulate channel sums\n",
    "        channel_sum += pixels.sum(dim=0)\n",
    "        \n",
    "        # Update the total number of pixels\n",
    "        total_pixels += pixels.shape[0]\n",
    "\n",
    "    # Compute mean values for each channel\n",
    "    channel_mean = channel_sum / total_pixels\n",
    "\n",
    "    for path_image in tqdm(list_path_image, desc='Compute squared diff sum by channel'):\n",
    "        # Open the image\n",
    "        image = read_tif(path_image)\n",
    "        image = image / max_channels\n",
    "            \n",
    "        # Reshape the image to a 2D array of pixels (height * width, channels)\n",
    "        pixels = image.view(-1, num_channels)\n",
    "        \n",
    "        # Accumulate squared differences from the mean\n",
    "        diff = pixels - channel_mean\n",
    "        channel_squared_diff_sum += (diff * diff).sum(dim=0)\n",
    "\n",
    "    # Compute standard deviation values for each channel\n",
    "    channel_std = torch.sqrt(channel_squared_diff_sum / total_pixels)\n",
    "\n",
    "    dataset_dict = {\n",
    "        'mean': channel_mean.tolist(),\n",
    "        'std': channel_std.tolist()\n",
    "    }\n",
    "\n",
    "    with open(filename, 'w', encoding='UTF8') as f:\n",
    "        json.dump(dataset_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 10, 207, 207)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../data/raw/train/sen/D004_2021/Z1_NN/sen/SEN2_sp_D004_2021-Z1_NN_data.npy').reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_path_image = os.path.join(os.pardir, 'data', 'raw', 'train', 'sen', '**', '*.npy')\n",
    "filename = os.path.join(os.pardir, 'data', 'raw', 'sen_pixels_metadata.json')\n",
    "compute_stats(template_path_image, filename, 5, np.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5043, -0.6432, -0.7127,  ..., -0.2785,  0.0167, -0.1570],\n",
       "         [-0.6259, -0.6953, -0.6259,  ..., -0.0701, -0.2438, -0.3306],\n",
       "         [-0.7127, -0.7648, -0.5217,  ..., -0.1222, -0.5043, -0.4696],\n",
       "         ...,\n",
       "         [-1.2684, -1.2684, -1.2858,  ...,  0.6245, -0.0528, -0.1222],\n",
       "         [-1.2858, -1.2684, -1.2684,  ...,  0.4161,  0.0514, -0.0180],\n",
       "         [-1.2337, -1.2684, -1.2684,  ...,  0.3293,  0.3293, -0.1222]],\n",
       "\n",
       "        [[-0.4348, -0.5738, -0.6432,  ..., -0.1917,  0.1383, -0.0701],\n",
       "         [-0.5738, -0.6259, -0.5564,  ...,  0.0167, -0.1570, -0.2438],\n",
       "         [-0.6606, -0.6606, -0.4696,  ..., -0.0180, -0.4175, -0.4175],\n",
       "         ...,\n",
       "         [-1.0600, -1.0948, -1.1121,  ...,  0.7461,  0.0167, -0.1049],\n",
       "         [-1.0948, -1.0600, -1.0948,  ...,  0.5724,  0.0862,  0.0514],\n",
       "         [-1.0600, -1.0948, -1.0948,  ...,  0.4856,  0.4682, -0.0701]],\n",
       "\n",
       "        [[-0.5217, -0.6606, -0.6953,  ..., -0.1570,  0.2251,  0.0167],\n",
       "         [-0.6606, -0.7127, -0.6432,  ...,  0.0862, -0.1049, -0.2091],\n",
       "         [-0.7648, -0.7648, -0.5217,  ..., -0.0180, -0.4175, -0.3480],\n",
       "         ...,\n",
       "         [-0.9037, -0.9037, -0.9211,  ...,  0.6766, -0.1049, -0.2091],\n",
       "         [-0.9037, -0.8690, -0.9037,  ...,  0.4335, -0.0180, -0.0528],\n",
       "         [-0.8690, -0.9037, -0.9037,  ...,  0.3293,  0.3293, -0.2438]],\n",
       "\n",
       "        [[-0.4348, -0.5043, -0.5217,  ..., -0.9385, -0.7301, -0.8343],\n",
       "         [-0.5043, -0.5738, -0.4696,  ..., -0.8343, -0.9211, -0.9385],\n",
       "         [-0.6259, -0.6432, -0.3827,  ..., -0.9211, -1.0427, -1.0427],\n",
       "         ...,\n",
       "         [-1.4595, -1.4595, -1.4595,  ..., -0.7648, -1.0948, -1.1121],\n",
       "         [-1.4595, -1.4595, -1.4595,  ..., -0.9037, -1.0774, -1.0948],\n",
       "         [-1.4595, -1.4595, -1.4595,  ..., -0.9732, -0.9732, -1.1469]],\n",
       "\n",
       "        [[-1.4768, -1.4768, -1.4768,  ..., -1.5984, -1.5984, -1.5984],\n",
       "         [-1.4768, -1.4595, -1.4595,  ..., -1.5984, -1.5984, -1.5984],\n",
       "         [-1.4595, -1.4595, -1.4595,  ..., -1.5984, -1.5984, -1.5984],\n",
       "         ...,\n",
       "         [-1.5984, -1.5984, -1.5984,  ..., -1.1990, -1.1990, -1.1990],\n",
       "         [-1.5984, -1.5984, -1.5984,  ..., -1.1990, -1.2163, -1.2163],\n",
       "         [-1.5984, -1.5984, -1.5984,  ..., -1.2163, -1.2163, -1.2163]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = read_tif('../data/raw/train/aerial/D004_2021/Z1_NN/img/IMG_000001.tif')\n",
    "image = image / 255.00\n",
    "filename = os.path.join(os.pardir, 'data', 'aerial_pixels_metadata.json')\n",
    "with open(filename) as f:\n",
    "    stats = json.load(f)\n",
    "T.Normalize(mean=stats['mean'], std=stats['std'])(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flair-2-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
